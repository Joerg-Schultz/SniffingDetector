{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sniffingDir = \"data/train/Sniffing\"\n",
    "backgroundDir = \"data/train/Background\"\n",
    "testSniffingDir = \"data/test/Sniffing\"\n",
    "testBackgroundDir = \"data/test/Background\"\n",
    "\n",
    "validation_fraction = 0.2\n",
    "\n",
    "correct_class_imbalance = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "import pathlib\n",
    "from dvc.api import DVCFileSystem\n",
    "\n",
    "#import numpy as np\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "from tensorflow.python.ops import gen_audio_ops as audio_ops\n",
    "\n",
    "#  enable NumPy behavior for TensorFlow:\n",
    "tnp.experimental_enable_numpy_behavior()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def generate_spectrogram(file_path, label):\n",
    "    # does not scale as sniffing should be the same independent of background level\n",
    "    audio_tensor = tfio.audio.AudioIOTensor(file_path, dtype=tf.int16)\n",
    "    audio = tf.cast(audio_tensor[:], tf.float32)\n",
    "    spectrogram = audio_ops.audio_spectrogram(audio,\n",
    "                                              window_size=320,\n",
    "                                              stride=160,\n",
    "                                              magnitude_squared=True)\n",
    "    spectrogram = tf.nn.pool(\n",
    "        input=tf.expand_dims(spectrogram, -1),\n",
    "        window_shape=[1, 6],\n",
    "        strides=[1, 6],\n",
    "        pooling_type='AVG',\n",
    "        padding='SAME')\n",
    "    spectrogram = tf.squeeze(spectrogram, axis=0)\n",
    "    # Not sure whether the log is a good idea...\n",
    "    spectrogram = tnp.log10(spectrogram + 1e-6)\n",
    "    return spectrogram, label\n",
    "\n",
    "def prepare_data(dir, value):\n",
    "    filePath = os.path.join(dir, \"*.wav\")\n",
    "    files = tf.data.Dataset.list_files(filePath)\n",
    "    file_count = len(files)\n",
    "    #values = tf.zeros(len(files)) if value == 0 else tf.ones(len(files))\n",
    "    if value == 0:\n",
    "        values = tf.concat([tf.zeros(shape=[file_count, 1]), tf.ones(shape=[file_count, 1])], axis=1)\n",
    "    else:\n",
    "        values = tf.concat([tf.ones(shape=[file_count, 1]), tf.zeros(shape=[file_count, 1])], axis=1)\n",
    "\n",
    "    data = tf.data.Dataset.zip((files, tf.data.Dataset.from_tensor_slices(values)))\n",
    "    spectrogramData = data.map(generate_spectrogram)\n",
    "    return spectrogramData\n",
    "\n",
    "def generate_binary_dataset(trueDataDir, falseDataDir):\n",
    "    trueData = prepare_data(trueDataDir, 1)\n",
    "    true_number = trueData.cardinality().numpy()\n",
    "    print(f\"Sniffing Datasets: {true_number}\")\n",
    "    falseData = prepare_data(falseDataDir, 0)\n",
    "    false_number = falseData.cardinality().numpy()\n",
    "    print(f\"Background Datasets: {false_number}\")\n",
    "    if correct_class_imbalance:\n",
    "        falseData = falseData.shuffle(false_number).take(true_number)\n",
    "        false_number = falseData.cardinality().numpy()\n",
    "        print(f\"Corrected Background Datasets: {false_number}\")\n",
    "    combinedData = trueData.concatenate(falseData)\n",
    "    combinedData = combinedData.cache()\n",
    "    return combinedData.shuffle(buffer_size=combinedData.cardinality().numpy())\n",
    "\n",
    "def split_validation(allData, fraction):\n",
    "    numberDataSets = allData.cardinality().numpy()\n",
    "    validationCount = round(numberDataSets * fraction)\n",
    "    trainSet = allData.take(numberDataSets - validationCount)\n",
    "    validationSet = allData.skip(numberDataSets - validationCount).take(validationCount)\n",
    "    return trainSet, validationSet\n",
    "\n",
    "def batch_prefetch(dataSet):\n",
    "    dataSet = dataSet.batch(16)\n",
    "    dataSet = dataSet.prefetch(8)\n",
    "    return dataSet\n",
    "\n",
    "def calc_accuracy(predictions, true_values):\n",
    "    accuracy = sum(map(lambda x, y: x == y == 1, true_values, predictions))/sum(true_values)\n",
    "    return accuracy\n",
    "\n",
    "def representative_data_gen():\n",
    "    repr_samples, repr_labels = train.as_numpy_iterator().next()\n",
    "    yield [repr_samples]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sniffing Datasets: 251\n",
      "Background Datasets: 772\n",
      "inputShape (99, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "data = generate_binary_dataset(trueDataDir=sniffingDir, falseDataDir=backgroundDir)\n",
    "train, validation = split_validation(data, validation_fraction)\n",
    "train = batch_prefetch(train)\n",
    "validation = batch_prefetch(validation)\n",
    "samples, labels = train.as_numpy_iterator().next()\n",
    "inputShape = samples.shape[1:]\n",
    "print(f\"inputShape {inputShape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_layer1 (Conv2D)        (None, 99, 43, 4)         40        \n",
      "                                                                 \n",
      " max_pooling1 (MaxPooling2D)  (None, 49, 21, 4)        0         \n",
      "                                                                 \n",
      " conv_layer2 (Conv2D)        (None, 49, 21, 4)         148       \n",
      "                                                                 \n",
      " max_pooling2 (MaxPooling2D)  (None, 24, 10, 4)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 960)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 960)               0         \n",
      "                                                                 \n",
      " hidden_layer1 (Dense)       (None, 40)                38440     \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 82        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,710\n",
      "Trainable params: 38,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(4, 3,\n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           name='conv_layer1',\n",
    "           input_shape=inputShape),\n",
    "    MaxPooling2D(name='max_pooling1', pool_size=(2,2)),\n",
    "    Conv2D(4, 3,\n",
    "           padding='same',\n",
    "           activation='relu',\n",
    "           name='conv_layer2'),\n",
    "    MaxPooling2D(name='max_pooling2', pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(\n",
    "        40,\n",
    "        activation='relu',\n",
    "        name='hidden_layer1'\n",
    "    ),\n",
    "    Dense(\n",
    "        2, # TODO test 2 output nodes\n",
    "        activation='softmax',\n",
    "        name='output'\n",
    "    )\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2912 - recall_2: 0.8826 - precision_2: 0.8826 - val_loss: 0.2479 - val_recall_2: 0.9073 - val_precision_2: 0.9073\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2725 - recall_2: 0.8863 - precision_2: 0.8863 - val_loss: 0.2598 - val_recall_2: 0.9073 - val_precision_2: 0.9073\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.3124 - recall_2: 0.8692 - precision_2: 0.8692 - val_loss: 0.1999 - val_recall_2: 0.9268 - val_precision_2: 0.9268\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2621 - recall_2: 0.8985 - precision_2: 0.8985 - val_loss: 0.2049 - val_recall_2: 0.9317 - val_precision_2: 0.9317\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2589 - recall_2: 0.8961 - precision_2: 0.8961 - val_loss: 0.1870 - val_recall_2: 0.9317 - val_precision_2: 0.9317\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2538 - recall_2: 0.8802 - precision_2: 0.8802 - val_loss: 0.1971 - val_recall_2: 0.9268 - val_precision_2: 0.9268\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2443 - recall_2: 0.8888 - precision_2: 0.8888 - val_loss: 0.1708 - val_recall_2: 0.9366 - val_precision_2: 0.9366\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2332 - recall_2: 0.9010 - precision_2: 0.9010 - val_loss: 0.1629 - val_recall_2: 0.9463 - val_precision_2: 0.9463\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2199 - recall_2: 0.9120 - precision_2: 0.9120 - val_loss: 0.1580 - val_recall_2: 0.9561 - val_precision_2: 0.9561\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2149 - recall_2: 0.9144 - precision_2: 0.9144 - val_loss: 0.1447 - val_recall_2: 0.9610 - val_precision_2: 0.9610\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2193 - recall_2: 0.9071 - precision_2: 0.9071 - val_loss: 0.1484 - val_recall_2: 0.9659 - val_precision_2: 0.9659\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.2169 - recall_2: 0.9120 - precision_2: 0.9120 - val_loss: 0.1269 - val_recall_2: 0.9610 - val_precision_2: 0.9610\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.2308 - recall_2: 0.9046 - precision_2: 0.9046 - val_loss: 0.1406 - val_recall_2: 0.9707 - val_precision_2: 0.9707\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.2104 - recall_2: 0.9108 - precision_2: 0.9108 - val_loss: 0.1552 - val_recall_2: 0.9561 - val_precision_2: 0.9561\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1930 - recall_2: 0.9218 - precision_2: 0.9218 - val_loss: 0.1205 - val_recall_2: 0.9610 - val_precision_2: 0.9610\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1837 - recall_2: 0.9291 - precision_2: 0.9291 - val_loss: 0.1281 - val_recall_2: 0.9317 - val_precision_2: 0.9317\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1722 - recall_2: 0.9291 - precision_2: 0.9291 - val_loss: 0.1128 - val_recall_2: 0.9756 - val_precision_2: 0.9756\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1966 - recall_2: 0.9193 - precision_2: 0.9193 - val_loss: 0.1114 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1702 - recall_2: 0.9364 - precision_2: 0.9364 - val_loss: 0.1062 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.1677 - recall_2: 0.9303 - precision_2: 0.9303 - val_loss: 0.0959 - val_recall_2: 0.9707 - val_precision_2: 0.9707\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.1722 - recall_2: 0.9254 - precision_2: 0.9254 - val_loss: 0.1708 - val_recall_2: 0.9415 - val_precision_2: 0.9415\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1835 - recall_2: 0.9193 - precision_2: 0.9193 - val_loss: 0.1134 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1547 - recall_2: 0.9364 - precision_2: 0.9364 - val_loss: 0.1048 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 1s 15ms/step - loss: 0.1428 - recall_2: 0.9511 - precision_2: 0.9511 - val_loss: 0.0819 - val_recall_2: 0.9854 - val_precision_2: 0.9854\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1515 - recall_2: 0.9438 - precision_2: 0.9438 - val_loss: 0.1216 - val_recall_2: 0.9610 - val_precision_2: 0.9610\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1531 - recall_2: 0.9413 - precision_2: 0.9413 - val_loss: 0.0811 - val_recall_2: 0.9854 - val_precision_2: 0.9854\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1542 - recall_2: 0.9377 - precision_2: 0.9377 - val_loss: 0.0747 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1497 - recall_2: 0.9364 - precision_2: 0.9364 - val_loss: 0.0887 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1360 - recall_2: 0.9499 - precision_2: 0.9499 - val_loss: 0.0842 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1748 - recall_2: 0.9303 - precision_2: 0.9303 - val_loss: 0.0690 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1480 - recall_2: 0.9401 - precision_2: 0.9401 - val_loss: 0.0815 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1429 - recall_2: 0.9560 - precision_2: 0.9560 - val_loss: 0.0597 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.1397 - recall_2: 0.9389 - precision_2: 0.9389 - val_loss: 0.0496 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1437 - recall_2: 0.9413 - precision_2: 0.9413 - val_loss: 0.0885 - val_recall_2: 0.9707 - val_precision_2: 0.9707\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1372 - recall_2: 0.9425 - precision_2: 0.9425 - val_loss: 0.0638 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1284 - recall_2: 0.9597 - precision_2: 0.9597 - val_loss: 0.0695 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1115 - recall_2: 0.9597 - precision_2: 0.9597 - val_loss: 0.0560 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1001 - recall_2: 0.9707 - precision_2: 0.9707 - val_loss: 0.0765 - val_recall_2: 0.9805 - val_precision_2: 0.9805\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1323 - recall_2: 0.9462 - precision_2: 0.9462 - val_loss: 0.0458 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1102 - recall_2: 0.9548 - precision_2: 0.9548 - val_loss: 0.0370 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1079 - recall_2: 0.9511 - precision_2: 0.9511 - val_loss: 0.0452 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1023 - recall_2: 0.9584 - precision_2: 0.9584 - val_loss: 0.0439 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1129 - recall_2: 0.9633 - precision_2: 0.9633 - val_loss: 0.0404 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0990 - recall_2: 0.9609 - precision_2: 0.9609 - val_loss: 0.0489 - val_recall_2: 0.9951 - val_precision_2: 0.9951\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1205 - recall_2: 0.9572 - precision_2: 0.9572 - val_loss: 0.0459 - val_recall_2: 0.9951 - val_precision_2: 0.9951\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1109 - recall_2: 0.9499 - precision_2: 0.9499 - val_loss: 0.0317 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1002 - recall_2: 0.9535 - precision_2: 0.9535 - val_loss: 0.0385 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1042 - recall_2: 0.9658 - precision_2: 0.9658 - val_loss: 0.0484 - val_recall_2: 0.9854 - val_precision_2: 0.9854\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.0994 - recall_2: 0.9633 - precision_2: 0.9633 - val_loss: 0.0396 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0951 - recall_2: 0.9645 - precision_2: 0.9645 - val_loss: 0.0281 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0813 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0440 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1119 - recall_2: 0.9548 - precision_2: 0.9548 - val_loss: 0.0234 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0984 - recall_2: 0.9597 - precision_2: 0.9597 - val_loss: 0.0255 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0736 - recall_2: 0.9768 - precision_2: 0.9768 - val_loss: 0.0342 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.1383 - recall_2: 0.9413 - precision_2: 0.9413 - val_loss: 0.0343 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0873 - recall_2: 0.9682 - precision_2: 0.9682 - val_loss: 0.0235 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0743 - recall_2: 0.9707 - precision_2: 0.9707 - val_loss: 0.0338 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0767 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0220 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0659 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0157 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.0637 - recall_2: 0.9792 - precision_2: 0.9792 - val_loss: 0.0131 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0560 - recall_2: 0.9866 - precision_2: 0.9866 - val_loss: 0.0241 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0902 - recall_2: 0.9645 - precision_2: 0.9645 - val_loss: 0.0390 - val_recall_2: 0.9902 - val_precision_2: 0.9902\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0779 - recall_2: 0.9694 - precision_2: 0.9694 - val_loss: 0.0177 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0647 - recall_2: 0.9780 - precision_2: 0.9780 - val_loss: 0.0185 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0695 - recall_2: 0.9768 - precision_2: 0.9768 - val_loss: 0.0245 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0613 - recall_2: 0.9853 - precision_2: 0.9853 - val_loss: 0.0155 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0693 - recall_2: 0.9768 - precision_2: 0.9768 - val_loss: 0.0166 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0634 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0133 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0782 - recall_2: 0.9756 - precision_2: 0.9756 - val_loss: 0.0120 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0704 - recall_2: 0.9792 - precision_2: 0.9792 - val_loss: 0.0340 - val_recall_2: 0.9854 - val_precision_2: 0.9854\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0632 - recall_2: 0.9817 - precision_2: 0.9817 - val_loss: 0.0180 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0652 - recall_2: 0.9780 - precision_2: 0.9780 - val_loss: 0.0238 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0615 - recall_2: 0.9792 - precision_2: 0.9792 - val_loss: 0.0099 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0505 - recall_2: 0.9829 - precision_2: 0.9829 - val_loss: 0.0200 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.0546 - recall_2: 0.9817 - precision_2: 0.9817 - val_loss: 0.0083 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0555 - recall_2: 0.9768 - precision_2: 0.9768 - val_loss: 0.0089 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 0.0618 - recall_2: 0.9804 - precision_2: 0.9804 - val_loss: 0.0160 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 0.0551 - recall_2: 0.9792 - precision_2: 0.9792 - val_loss: 0.0307 - val_recall_2: 0.9951 - val_precision_2: 0.9951\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0611 - recall_2: 0.9731 - precision_2: 0.9731 - val_loss: 0.0140 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0532 - recall_2: 0.9853 - precision_2: 0.9853 - val_loss: 0.0076 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0574 - recall_2: 0.9780 - precision_2: 0.9780 - val_loss: 0.0124 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0598 - recall_2: 0.9756 - precision_2: 0.9756 - val_loss: 0.0168 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0405 - recall_2: 0.9878 - precision_2: 0.9878 - val_loss: 0.0094 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0600 - recall_2: 0.9719 - precision_2: 0.9719 - val_loss: 0.0117 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0565 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0095 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0502 - recall_2: 0.9792 - precision_2: 0.9792 - val_loss: 0.0135 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0481 - recall_2: 0.9829 - precision_2: 0.9829 - val_loss: 0.0071 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0360 - recall_2: 0.9927 - precision_2: 0.9927 - val_loss: 0.0061 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0299 - recall_2: 0.9914 - precision_2: 0.9914 - val_loss: 0.0055 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0359 - recall_2: 0.9890 - precision_2: 0.9890 - val_loss: 0.0061 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0447 - recall_2: 0.9853 - precision_2: 0.9853 - val_loss: 0.0057 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0377 - recall_2: 0.9878 - precision_2: 0.9878 - val_loss: 0.0037 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0388 - recall_2: 0.9866 - precision_2: 0.9866 - val_loss: 0.0073 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0312 - recall_2: 0.9914 - precision_2: 0.9914 - val_loss: 0.0045 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0478 - recall_2: 0.9841 - precision_2: 0.9841 - val_loss: 0.0121 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0399 - recall_2: 0.9890 - precision_2: 0.9890 - val_loss: 0.0050 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0306 - recall_2: 0.9914 - precision_2: 0.9914 - val_loss: 0.0044 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0551 - recall_2: 0.9743 - precision_2: 0.9743 - val_loss: 0.0073 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0417 - recall_2: 0.9878 - precision_2: 0.9878 - val_loss: 0.0076 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.0382 - recall_2: 0.9853 - precision_2: 0.9853 - val_loss: 0.0061 - val_recall_2: 1.0000 - val_precision_2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=100, validation_data=validation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sniffing Datasets: 64\n",
      "Background Datasets: 192\n",
      "16/16 [==============================] - 1s 6ms/step - loss: 0.7549 - recall_2: 0.7969 - precision_2: 0.7969\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.7548670768737793, 0.796875, 0.796875]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = generate_binary_dataset(trueDataDir=testSniffingDir, falseDataDir=testBackgroundDir)\n",
    "testData = batch_prefetch(testData)\n",
    "\n",
    "model.evaluate(testData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}